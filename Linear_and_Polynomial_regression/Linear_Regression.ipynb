{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.041</td>\n",
       "      <td>70.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>54.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.58</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.038</td>\n",
       "      <td>51.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.038</td>\n",
       "      <td>8.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.037</td>\n",
       "      <td>8.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.053</td>\n",
       "      <td>46.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.053</td>\n",
       "      <td>46.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.090</td>\n",
       "      <td>7.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.52</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.048</td>\n",
       "      <td>40.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.039</td>\n",
       "      <td>55.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.048</td>\n",
       "      <td>40.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             7.2              0.40         0.62           10.80      0.041   \n",
       "1             7.2              0.28         0.54           16.70      0.045   \n",
       "2             6.8              0.19         0.58           14.20      0.038   \n",
       "3             6.4              0.30         0.30            2.25      0.038   \n",
       "4             6.5              0.30         0.29            2.25      0.037   \n",
       "5             7.8              0.18         0.31           12.20      0.053   \n",
       "6             7.8              0.18         0.31           12.20      0.053   \n",
       "7             7.3              0.51         0.26            3.30      0.090   \n",
       "8             6.0              0.24         0.27            1.90      0.048   \n",
       "9             5.9              0.62         0.28            3.50      0.039   \n",
       "10            6.0              0.24         0.27            1.90      0.048   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  70.0                 189.0   0.9976  3.08       0.49   \n",
       "1                  54.0                 200.0   0.9990  3.08       0.49   \n",
       "2                  51.0                 164.0   0.9975  3.12       0.48   \n",
       "3                   8.0                 210.0   0.9937  3.20       0.62   \n",
       "4                   8.0                 210.0   0.9937  3.19       0.62   \n",
       "5                  46.0                 140.0   0.9980  3.06       0.53   \n",
       "6                  46.0                 140.0   0.9980  3.06       0.53   \n",
       "7                   7.0                 135.0   0.9944  3.01       0.52   \n",
       "8                  40.0                 170.0   0.9938  3.64       0.54   \n",
       "9                  55.0                 152.0   0.9907  3.44       0.44   \n",
       "10                 40.0                 170.0   0.9938  3.64       0.54   \n",
       "\n",
       "    alcohol  quality  \n",
       "0       8.6        4  \n",
       "1       9.5        6  \n",
       "2       9.6        6  \n",
       "3       9.9        6  \n",
       "4       9.9        5  \n",
       "5       8.9        6  \n",
       "6       8.9        6  \n",
       "7       8.8        5  \n",
       "8      10.0        7  \n",
       "9      12.0        6  \n",
       "10     10.0        7  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as alg\n",
    "\n",
    "x = pd.read_csv('winequality-white.csv',sep=';')\n",
    "x.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_linear_regression(filename, non_invertible, mapping, mapping_power):\n",
    "    white = pd.read_csv(filename, low_memory=False, sep=';').values\n",
    "    [N, d] = white.shape\n",
    "    if(mapping == True):\n",
    "        maped_X = mapping_data(white[:,:-1],mapping_power)\n",
    "        white = np.insert(maped_X, maped_X.shape[1], white[:,-1], axis=1)\n",
    "    np.random.seed(3)\n",
    "    \n",
    "    # prepare data\n",
    "    ridx = np.random.permutation(N)\n",
    "    ntr = int(np.round(N * 0.8))\n",
    "    nval = int(np.round(N * 0.1))\n",
    "    ntest = N - ntr - nval\n",
    "    \n",
    "    # spliting training, validation, and test\n",
    "    Xtrain = np.hstack([np.ones([ntr, 1]), white[ridx[0:ntr], 0:-1]])\n",
    "    ytrain = white[ridx[0:ntr], -1]\n",
    "    Xval = np.hstack([np.ones([nval, 1]), white[ridx[ntr:ntr + nval], 0:-1]])\n",
    "    yval = white[ridx[ntr:ntr + nval], -1]\n",
    "    Xtest = np.hstack([np.ones([ntest, 1]), white[ridx[ntr + nval:], 0:-1]])\n",
    "    ytest = white[ridx[ntr + nval:], -1]\n",
    "    if(non_invertible == True):\n",
    "        N, D = Xtrain.shape\n",
    "        np.random.seed(4)\n",
    "        random_row = np.random.randint(N)\n",
    "        random_col = np.random.randint(D)\n",
    "        Xtrain[:,random_col] = 0\n",
    "        Xtrain[random_row,:] = 0\n",
    "    return Xtrain, ytrain, Xval, yval, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(w, X, y):\n",
    "    ma_error = None\n",
    "    pred = X.dot(w)\n",
    "    ma_error = (abs(pred - y)).mean()\n",
    "    return ma_error\n",
    "\n",
    "def linear_regression_noreg(X, y):\n",
    "    weight = None\n",
    "    assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray)\n",
    "    weight = alg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return weight\n",
    "\n",
    "def linear_regression_invertible(X, y):\n",
    "    weight = None\n",
    "    mtx = X.T.dot(X)\n",
    "    temp = 0.1*np.identity(mtx.shape[0])\n",
    "    eig_val, eig_vec = alg.eig(mtx)\n",
    "    while np.abs(eig_val).min() < 0.00001:\n",
    "        mtx += temp\n",
    "        eig_val, eig_vec = alg.eig(mtx)\n",
    "    weight = alg.inv(mtx).dot(X.T).dot(y)\n",
    "    return weight\n",
    "\n",
    "def regularized_linear_regression(X, y, lambd):\n",
    "    weight = None\n",
    "    mtx = X.T.dot(X)\n",
    "    temp = lambd * np.identity(mtx.shape[0])\n",
    "    mtx += temp\n",
    "    weight = alg.inv(mtx).dot(X.T).dot(y)\n",
    "    return weight\n",
    "\n",
    "def tune_lambda(Xtrain, ytrain, Xval, yval):\n",
    "    best_lambda = None\n",
    "    best_abs_error = 99999.9\n",
    "    for k in range(-19, 20):\n",
    "        lamb = 10**k\n",
    "        weight = regularized_linear_regression(Xtrain, ytrain, lamb)\n",
    "        abs_error = mean_absolute_error(weight, Xval, yval)\n",
    "        if abs_error < best_abs_error:\n",
    "            best_lambda = lamb\n",
    "            best_abs_error = abs_error\n",
    "    return best_lambda\n",
    "\n",
    "def mapping_data(X, power):\n",
    "    pow_x = [X]\n",
    "    for k in range(1, power):\n",
    "        pow_x.append(pow_x[k-1]*X)\n",
    "    return np.concatenate(pow_x, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the model parameter is (12,).\n",
      "Model parameter is  [ 2.03721116e+02  1.09955585e-01 -1.93164831e+00 -4.90845229e-02\n",
      "  1.02194195e-01 -5.45232536e-02  4.00189587e-03  1.52537226e-04\n",
      " -2.04673020e+02  9.04608185e-01  6.41578531e-01  1.32320100e-01]\n",
      "MAE on train is ----> 0.58020\n",
      "MAE on val is ----> 0.59410\n",
      "MAE on test is ----> 0.56079\n",
      "*********************************************************************************************************************\n",
      "\n",
      "Dimensionality of the model parameter is (12,).\n",
      "Model parameter is  [ 1.72490981 -0.04898016 -2.05742338 -0.12068529  0.02838304 -0.81308859\n",
      "  0.00425276  0.          0.00675103  0.20653332  0.35756603  0.37653797]\n",
      "MAE on train is ----> 0.58509\n",
      "MAE on val is ----> 0.59939\n",
      "MAE on test is ----> 0.55777\n",
      "*********************************************************************************************************************\n",
      "\n",
      "Dimensionality of the model parameter is (12,).\n",
      "Model parameter is  [ 1.72490981 -0.04898016 -2.05742338 -0.12068529  0.02838304 -0.81308859\n",
      "  0.00425276  0.          0.00675103  0.20653332  0.35756603  0.37653797]\n",
      "MAE on train is ----> 0.58509\n",
      "MAE on val is ----> 0.59939\n",
      "MAE on test is ----> 0.55777\n",
      "*********************************************************************************************************************\n",
      "\n",
      "Best Lambda ====>  1e-15\n",
      "Ddimensionality of the model parameter is 12.\n",
      "Model parameter is  [ 2.03721116e+02  1.09955585e-01 -1.93164831e+00 -4.90845229e-02\n",
      "  1.02194195e-01 -5.45232538e-02  4.00189587e-03  1.52537226e-04\n",
      " -2.04673020e+02  9.04608185e-01  6.41578531e-01  1.32320100e-01]\n",
      "MAE on train is ----> 0.58020\n",
      "MAE on val is ----> 0.59410\n",
      "MAE on test is ----> 0.56079\n",
      "*********************************************************************************************************************\n",
      "\n",
      "Best Lambda ====>  1e-05\n",
      "Dimensionality of the model parameter is 23.\n",
      "Dodel parameter is  [ 1.25380815e+02  5.02384267e-01 -2.67773311e+00  9.80340233e-01\n",
      "  1.06212461e-01 -3.95578946e+00  2.39784392e-02  7.50076069e-03\n",
      " -3.12001013e+01 -4.86978603e+00  4.09420291e-01 -8.46119515e-01\n",
      " -2.72604969e-02  1.29686830e+00 -1.25860412e+00 -8.91481755e-04\n",
      "  1.57808283e+01 -2.28910275e-04 -2.75880957e-05 -8.24960621e+01\n",
      "  8.96138511e-01  1.80781412e-01  4.41502041e-02]\n",
      "MAE on train is ----> 0.56777\n",
      "MAE on val is ----> 0.57459\n",
      "MAE on test is ----> 0.57865\n",
      "*********************************************************************************************************************\n",
      "\n",
      "\n",
      "Best lambda is 1e-05\n",
      "when power = 2\n",
      "MAE on train is ----> 0.56777\n",
      "MAE on val is ----> 0.57459\n",
      "MAE on test is ----> 0.57865\n",
      "\n",
      "\n",
      "Best lambda is 0.0001\n",
      "when power = 3\n",
      "MAE on train is ----> 0.56318\n",
      "MAE on val is ----> 0.58117\n",
      "MAE on test is ----> 0.58448\n",
      "\n",
      "\n",
      "Best lambda is 0.0001\n",
      "when power = 4\n",
      "MAE on train is ----> 0.56024\n",
      "MAE on val is ----> 0.58280\n",
      "MAE on test is ----> 1.27799\n",
      "\n",
      "\n",
      "Best lambda is 0.01\n",
      "when power = 5\n",
      "MAE on train is ----> 0.55637\n",
      "MAE on val is ----> 0.57013\n",
      "MAE on test is ----> 4.99187\n",
      "\n",
      "\n",
      "Best lambda is 0.001\n",
      "when power = 6\n",
      "MAE on train is ----> 0.55416\n",
      "MAE on val is ----> 0.59193\n",
      "MAE on test is ----> 21.04536\n",
      "\n",
      "\n",
      "Best lambda is 0.1\n",
      "when power = 7\n",
      "MAE on train is ----> 0.55444\n",
      "MAE on val is ----> 0.58111\n",
      "MAE on test is ----> 115.07532\n",
      "\n",
      "\n",
      "Best lambda is 1000000\n",
      "when power = 8\n",
      "MAE on train is ----> 0.58764\n",
      "MAE on val is ----> 0.63641\n",
      "MAE on test is ----> 237.87904\n",
      "\n",
      "\n",
      "Best lambda is 100000\n",
      "when power = 9\n",
      "MAE on train is ----> 0.58825\n",
      "MAE on val is ----> 0.70155\n",
      "MAE on test is ----> 1220.89401\n",
      "\n",
      "\n",
      "Best lambda is 10000000\n",
      "when power = 10\n",
      "MAE on train is ----> 0.58919\n",
      "MAE on val is ----> 0.62606\n",
      "MAE on test is ----> 13972.70363\n",
      "\n",
      "\n",
      "Best lambda is 100000000\n",
      "when power = 11\n",
      "MAE on train is ----> 0.83600\n",
      "MAE on val is ----> 1.05488\n",
      "MAE on test is ----> 50685.03379\n",
      "\n",
      "\n",
      "Best lambda is 1000000000\n",
      "when power = 12\n",
      "MAE on train is ----> 2.88057\n",
      "MAE on val is ----> 3.60214\n",
      "MAE on test is ----> 280844.92530\n",
      "\n",
      "\n",
      "Best lambda is 100000000000000000\n",
      "when power = 13\n",
      "MAE on train is ----> 6.47904\n",
      "MAE on val is ----> 15.07487\n",
      "MAE on test is ----> 629747.58747\n",
      "\n",
      "\n",
      "Best lambda is 1000000000000000\n",
      "when power = 14\n",
      "MAE on train is ----> 12.24910\n",
      "MAE on val is ----> 46.24206\n",
      "MAE on test is ----> 5497839.17407\n",
      "\n",
      "\n",
      "Best lambda is 100000000000000\n",
      "when power = 15\n",
      "MAE on train is ----> 78.11573\n",
      "MAE on val is ----> 76.68189\n",
      "MAE on test is ----> 47437884.59886\n",
      "\n",
      "\n",
      "Best lambda is 100000000000000000\n",
      "when power = 16\n",
      "MAE on train is ----> 47.53815\n",
      "MAE on val is ----> 99.00093\n",
      "MAE on test is ----> 60658070.77367\n",
      "\n",
      "\n",
      "Best lambda is 100000000000\n",
      "when power = 17\n",
      "MAE on train is ----> 187.89226\n",
      "MAE on val is ----> 200.06208\n",
      "MAE on test is ----> 1592701209.39754\n",
      "\n",
      "\n",
      "Best lambda is 1000000000000\n",
      "when power = 18\n",
      "MAE on train is ----> 105.75582\n",
      "MAE on val is ----> 208.31349\n",
      "MAE on test is ----> 648070274.31670\n",
      "\n",
      "\n",
      "Best lambda is 10000000000000\n",
      "when power = 19\n",
      "MAE on train is ----> 316.17429\n",
      "MAE on val is ----> 383.09203\n",
      "MAE on test is ----> 2619568351.97208\n"
     ]
    }
   ],
   "source": [
    "filename = 'winequality-white.csv'\n",
    "\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, False, False, 0)\n",
    "w = linear_regression_noreg(Xtrain, ytrain)\n",
    "print(\"Dimensionality of the model parameter is \", w.shape, \".\", sep=\"\")\n",
    "print(\"Model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is ----> %.5f\" % mae)\n",
    "\n",
    "print('*********************************************************************************************************************')\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, True, False, 0)\n",
    "w = linear_regression_invertible(Xtrain, ytrain)\n",
    "print(\"\\nDimensionality of the model parameter is \", w.shape, \".\", sep=\"\")\n",
    "print(\"Model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is ----> %.5f\" % mae)\n",
    "\n",
    "print('*********************************************************************************************************************')\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, True, False, 0)\n",
    "w = regularized_linear_regression(Xtrain, ytrain, 0.1)\n",
    "print(\"\\nDimensionality of the model parameter is \", w.shape, \".\", sep=\"\")\n",
    "print(\"Model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is ----> %.5f\" % mae)\n",
    "\n",
    "print('*********************************************************************************************************************')\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, False, False, 0)\n",
    "bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval)\n",
    "print(\"\\nBest Lambda ====>  \" + str(bestlambd))\n",
    "w = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "print(\"Ddimensionality of the model parameter is \", len(w), \".\", sep=\"\")\n",
    "print(\"Model parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is ----> %.5f\" % mae)\n",
    "\n",
    "print('*********************************************************************************************************************')\n",
    "power = 2\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, False, True, power)\n",
    "bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval)\n",
    "print(\"\\nBest Lambda ====>  \", bestlambd, sep=\"\")\n",
    "w = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "print(\"Dimensionality of the model parameter is \", len(w), \".\", sep=\"\")\n",
    "print(\"Dodel parameter is \", np.array_str(w))\n",
    "mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "print(\"MAE on train is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xval, yval)\n",
    "print(\"MAE on val is ----> %.5f\" % mae)\n",
    "mae = mean_absolute_error(w, Xtest, ytest)\n",
    "print(\"MAE on test is ----> %.5f\" % mae)\n",
    "\n",
    "print('*********************************************************************************************************************')\n",
    "power = 20\n",
    "for i in range(2, power):\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_linear_regression(filename, False, True, i)\n",
    "    bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval)\n",
    "    print('\\n\\nBest lambda is ' + str(bestlambd))\n",
    "    w = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "    mae = mean_absolute_error(w, Xtrain, ytrain)\n",
    "    print('when power = ' + str(i))\n",
    "    print(\"MAE on train is ----> %.5f\" % mae)\n",
    "    mae = mean_absolute_error(w, Xval, yval)\n",
    "    print(\"MAE on val is ----> %.5f\" % mae)\n",
    "    mae = mean_absolute_error(w, Xtest, ytest)\n",
    "    print(\"MAE on test is ----> %.5f\" % mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
